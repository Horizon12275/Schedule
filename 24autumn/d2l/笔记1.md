## 数据操作

1. 4 维数据：可以用于存储 RGB 图片的批量（批量大小，通道数，高度，宽度）。

2. 5 维数据：可以用于存储视频的批量（批量大小，通道数，帧数，高度，宽度）。

3. 矩阵范数：[链接](https://blog.csdn.net/weixin_43660703/article/details/108422077)

4. 特征向量：不被矩阵改变方向的向量。

5. python 里面 B = A.clone()才会分配新的内存空间，B = A 则是指向同一块内存空间。

6. 向量和向量和标量求导之后会得到不同的行列的矩阵结果。几何意义：等高线的梯度

7. 求导的输入也可以扩展到矩阵

8. 向量求导存在链式法则、可用于中间展开和扩展

9. 自动求导：使用计算图（pytorch 使用隐式构造），有两种模式，正向传播和反向传播

10. 反向可以剩内存，因为可以剪枝，内存 O(1)

11. 耗 gpu 的原因就是计算梯度的时候要把先前的值存下来

12. 基本上是对标量自动求导，而不是对向量自动求导

13. 深度学习框架可以自动计算导数：我们首先将梯度附加到想要对其计算偏导数的变量上，然后记录目标值的计算，执行它的反向传播函数，并访问得到的梯度。

## 线性回归

0. 线性回归是对 n 维输入的加权，外加偏差

1. 线性模型可以看作是单层神经网络（带权重的层数是 1）

2. 衡量预测质量：平方损失：(y - y_hat)^2 \* 0.5 （有 0.5 是为了求导的时候系数抵消）

3. 训练损失：是所有样本的平均损失（有公式）

4. 最小化损失来学习参数

5. 线性回归有显式解

## 基础优化方法

1. 梯度下降，需要人为选定学习率 n（超参数）（不能走太小，因为计算梯度开销大）

2. 小批量随机梯度下降：每次迭代时随机抽取一小批量样本来计算梯度（因为在整个训练集上计算梯度开销大）b 是批量大小，也是超参数（不能太小，不然没法充分利用 gpu 并行计算的资源）（也不能太大，可能内存不够或者浪费计算）

3. 梯度下降不断沿着梯度的反方向更新参数，直到达到最小值（沿着梯度的正方向的话，损失会增大）

## 线性回归实现

1. 标签值：指定的真实值

2. num_epochs: 迭代次数

```python
# 从零开始实现
def sgd(params, lr, batch_size):  #@save
    """小批量随机梯度下降"""
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size ###注意这里的param.grad是因为在下面的l.sum().backward()计算了梯度，除以batch_size是因为l.sum()得到的是一个batch_size大小的和，要平均一下
            param.grad.zero_()

for epoch in range(num_epochs):
    for X, y in data_iter(batch_size, features, labels):
        l = loss(net(X, w, b), y)  # X和y的小批量损失
        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，
        # 并以此计算关于[w,b]的梯度
        l.sum().backward() ### 注意这里计算backward是为了上面的sgd函数里的param.grad能够有值
        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数
    with torch.no_grad(): # 禁止计算梯度，从而提高效率和节省内存
        train_l = loss(net(features, w, b), labels)
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
```

```python
# 简洁实现
net = nn.Sequential(nn.Linear(2, 1))
# Sequential是一个容器，可以把多个模块串联起来，模块将按照在传入Sequential的顺序依次被添加到计算图中执行
# 这里的Linear是一个线性层，它有两个输入特征和一个输出特征
net[0].weight.data.normal_(0, 0.01) # 初始化权重
net[0].bias.data.fill_(0) # 初始化偏差
# 这里用net[0]来访问网络中的第一个图层，即访问第一个图层的权重（weight）和偏差（bias）

trainer = torch.optim.SGD(net.parameters(), lr=0.03) # 批量随机梯度下降

num_epochs = 3
for epoch in range(num_epochs):
    for X, y in data_iter:
        l = loss(net(X) ,y)
        trainer.zero_grad() # 这里的trainer是torch.optim.SGD(net.parameters(), lr=0.03)的实例，zero_grad()函数可以将梯度清零
        l.backward()
        trainer.step() # trainer.step()调用SGD算法来更新权重和偏差
    l = loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {l:f}')
```

## 常见损失函数

1. 均方误差：(y - y_hat)^2 \* 0.5

2. 交叉熵损失函数：-log(y_hat)（y_hat 是预测概率，y 是真实概率）

3. 绝对值误差：|y - y_hat|

4. Huber 损失：平方误差和绝对值误差的折中，当误差很小时，使用平方误差，当误差很大时，使用绝对值误差

## 基本操作

1. transform 是一个数据预处理的操作，用于将输入数据（如图像）转换为模型可以接受的格式。

```python
trans = transforms.ToTensor()
mnist_train = torchvision.datasets.FashionMNIST(
    root="../data", train=True, transform=trans, download=True)
mnist_test = torchvision.datasets.FashionMNIST(
    root="../data", train=False, transform=trans, download=True)
```

2. 图像的通道数表示图像中颜色信息的数量。常见的通道数包括：

   - 灰度图像: 只有一个通道，表示亮度信息。通道数为 1。

   - RGB 彩色图像: 有三个通道，分别表示红色、绿色和蓝色。通道数为 3。

   - RGBA 彩色图像: 除了 RGB 三个通道外，还有一个 alpha 通道，用于表示透明度。通道数为 4。

   - 在 PyTorch 中，图像张量的形状通常是 (C, H, W)，其中 C 是通道数，H 是高度，W 是宽度。例如，一幅 RGB 图像的形状可能是 (3, 32, 32)，表示它有 3 个颜色通道，且每个通道的尺寸为 32x32 像素。

3. 需要注意读取数据所耗的时间，和训练计算的时间对比

## softmax 回归

1. 回归估计的是一个连续值，分类预测的是一个离散类别

2. 回归：单连续数值输出；自然区间 R；跟真实值的区别作为损失

3. 分类：通常多个输出；输出是第 i 类的置信度
