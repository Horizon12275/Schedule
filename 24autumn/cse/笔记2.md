## 11 Before-or-after atomicity and Serializability

1. 为了防止这个 log 不断地变大、需要引入一个 checkpoint 机制，即定期地将 log 中的内容进行决定、决定哪些可以扔掉、然后扔掉可以扔掉的

2. naive 的方法：全部跑一遍 recovery，但是太慢了、

   - For redo logging, we only need to flush the page caches so we can discard all the logs of committed TXs
   - For undo logging, we only need to wait for TXs to finish to discard all its log entries

3. 做 basic checkpoint 的方法

   - 等到当前没有 transaction 在运行的时候，就可以做 checkpoint 了
   - 然后 flush page cache，然后把所有的 log 都写到 disk 上
   - 然后把 logs 都扔掉
   - 不过会有问题：就算一个 transaction 运行了很长时间

4. 改进的 checkpoint 方法

   - 等到当前没有任何操作进行的时候（如果正在写的话、会有正确性的问题）
   - 写一个 CKPT 记号到 log 中
     - 包含了当前所有正在运行的 transaction 的 ID 和他们的 log
   - 然后 flush 一下 page cache
   - 然后把所有 log 都删了、除了 CKPT 中正在运行的 transaction 的 log

5. 对于 ppt 上的例子

   - T1 就不需要做任何事情了
   - T2 需要做 redo、从 checkpoint 开始
   - T3 需要做 redo、从它自己的 log entry 开始
   - T4 因为没有 commit，所以需要做 undo、从它自己的 log entry 开始（和 CKP 也要做）
   - T5 因为没有 commit，所以需要做 undo、从它自己的 log entry 开始

6. Question:

   - Which one is faster during execution?
   - Which one is faster during recovery?

7. Redo-only logging 在正常执行的时候的性能更好

   - Less disk operations compared with undo-redo logging
   - Only need one scan of the entire log file

8. Redo-only logging is typically preferred except for TXs with large in-memory states （除了对于大的文件）

9. undo-only logging 没有那么常用、因为性能不好、除了恢复的时候

10. Logging 也是一种保证 durability 的方法

11. 下面开始讲 before-or-after atomicity

12. 计算机需要将实际上并行进行的操作、整理成一个逻辑上的串行操作

13. 因为这个操作会有 race condition，然后这个 race condition 是很难控制的

14. before-or-after 和 linearizability 是不同的

15. Concurrent actions have the before-or-after property if their effect from the point of view of their invokers is as if the actions occurred either completely before or completely after one another （并发的操作有 before-or-after 的性质、如果他们的效果、从调用者的角度来看、就好像这些操作要么完全在前面、要么完全在后面）

16. before-or-after 要解决 race condition 的问题， need a group of reads/writes to be atomic

17. 对于 before-or-after 的实现、需要用到锁

18. 如果用全局的大锁、那么每次操作都要拿锁和释放锁、性能会很差（粒度太粗了）

19. 可以做 fine-grained locking，比如做一个 lock table、对数组里的每个数据项都有一个锁

20. 但是 ppt 上的有一个例子显示了、就是在多个函数中的时候、用这个 fine-grained locking 还是会出现 race condition 的问题

21. 所以引入了一个 two-phase locking protocol

    - 就是基于 fine-grained locking 的实现、需要操作哪些数据的时候就获取锁、但是只有当所有的操作都执行完之后、才会释放锁

22. 但是 fine-grained lock 对于每个数字都有一个锁、太浪费内存了

23. 什么是线性的操作顺序？貌似和另外一门课上的概念一样

24. 有时候最终结果是对的、但是并不是完全线性的

25. 所以有了不同的 serializability 的分类

    - final state serializability
    - conflict serializability （最广泛使用的）（条件最强）
    - view serializability

26. Two operations conflict if:

    - they operate on the same data object, and
    - at least one of them is write, and
    - they belong to different transactions

27. conflict serializability:

    - A schedule is conflict serializable if the order of its conflicts (the order in which the conflicting operations occur) is the same as the order of conflicts in some sequential schedule (可以从一个串行的 schedule 中找到一个和当前 schedule 的冲突顺序一样的 schedule)

28. PPT 上有 conflict 的例子

    - 这样就能构建一个 conflict graph
    - 如果这个 graph 是 acyclic 的、那么就是 conflict serializable 的
    - （按照执行顺序、可以从 T1 到 T2 画边，或者 T2 到 T1 画边）
    - 那就只需要检查这个图就可以了（如果有环、就不是 conflict serializable 的）

29. 但是又有一个例子、就是结果可以符合线性的，但是上面有环、引入了 view serializability.不过貌似这个第一个例子是 final-state serializabile 的，还有一个是 view serializable 的（这个操作会被另一个线程擦除）

30. view serializability:

    - A schedule is view serializable if the final written state as well as intermediate reads are the same as in some serial schedule
    - ppt 上也有详细定义

31. final-state > view > conflict （包含）

32. 2pl 是能很简单实现 conflict serializability 的

    - 即证明这个操作没有环，用反证法
    - 因为 T1 必须要在执行完之后再放锁

33. 但是有时候 2pl 也不能保证实现 conflict serializability

    - 主要是因为这个 update 需要扫一遍 list
    - 会出现幻读
    - 解决方法：1. 用 predicate lock 2. 用 index lock（在 B+ tree 上加 range locks）3. 有时候忽略这个问题（性能）
    - 什么时候能保证：所有数据 conflict 都被一把锁给识别出来了。

## 12 Serializability, OCC & Transaction

1. 这个 2pl 会导致死锁，解决方法：

   - 在一个 pre-defined order 中获取锁
   - 用 conflict graph 来检测死锁，如果有环、就死锁了、然后可以 abort 一个 transaction（这个方法不太好，成环监测代价太大）
   - using heuriestics to pre-abort the TXs that are likely to cause deadlocks（heuriestics 即启发式算法，比如说用一个 timeout 的时间来检测死锁，超过就 abort）

2. 产生死锁的原因：

   - 因为 2pl 是悲观的，来避免 race condition

3. 所以能不能以乐观的方式去处理这个问题呢？即 Optimistic Concurrency Control，即 OCC

4. 乐观地去拿锁、然后 commit 的时候再检查一下

5. OCC 执行 transaction 的三个阶段：

   - 阶段 1：Concurrent local processing:
     - Read data into a read set
     - Write data into a write set
     - 写的时候，如果这个变量已经被读过了，也要写到 read set 里面
     - 读的时候、如果这个变量已经被读过了、也要先从 read set 里面读
   - 阶段 2：Validation serializability in critical section:
     - Check whether serializability is guaranteed
     - 看一看这个数据是不是被改过了，看一看 read set 里面的值和 commit 时候的值是不是一样（类似地、会有一个 ABA 的问题，即他的值是一样的、但是其实是被改过了、所以在记录数据的时候可以再记录一个版本号，比较的时候比较版本号就可以了）
   - 阶段 3：Commit or abort:
     - If validation is successful, commit
     - If validation fails, abort
     - critical section 就是里面那个监测的步骤、也需要保证 before-or-after atomicity （如何保证、第 2，3 阶段里、让这个提交的函数时候加一把大锁）

6. occ 能不能避免 2pl 的死锁呢？

   - 可以避免死锁，把这个 readset 和 writeset 都排序一下，再用 2pl

7. 一个 occ 用 2pl 的优化：

   - 可以不用拿 read lock，只用拿 write lock（因为有一个监测是否改动过在）
   - 但是也是不完全等价的，所以要判断这个 d 在 read set 里面有没有被上锁，如果上锁了、就判断为 abort

8. 所以 occ 相对于 2pl 的优势：

   - occ 对于读操作不需要加锁，只有在 commit 的时候才加锁

9. 锁的实现：从可以从软件或者从硬件的层面进行实现
   - spin lock 的开销很大

## 13 OCC, MVCC, TX & Multi-site atomicity

1. Occ 会导致 false aborts 的情况、即一个事务被 abort 了、但是其实是没有冲突的

   - 特别是对于一个长时间的多读的 transaction
   - 即 occ 的问题是活锁 livelock
   - 解决的方法是设置一个 retry limit，如果 abort 次数超过这个 limit，就 delay 其他的 transaction，让这个 transaction 先执行

2. Occ 和 2pl 没有哪个绝对更好，可以混合使用

3. hardware transactional memory(HTM) 是 cpu 的一种特性、为了并发地写（保证了 before-or-after atomicity）

   - Intel 实现了一个 restricted transactional memory(RTM)

4. 怎么用 HTM（RTM）

   - XBEGIN()
   - XEND()
   - 如果监测到了冲突，就会 abort，然后 rollback 到 XBEGIN() 的地方，也可以手动 xabort

5. RTM 的好处和坏处：

   - 好处：保证原子性、然后性能更好
   - 坏处：不能保证成功（因为本质是在硬件上实现了一个 OCC）

6. RTM 的实现：

   - 复用了 CPU cache 去存储这个 transaction 的 read set 和 write set
   - 用了 cache coherence protocol 去检查冲突
   - 但是这就导致了硬件的限制、比如说 cpu cache 的大小是有限的
   - RTM 的 read wirte sets 大小依靠很多因素（ppt 上）

7. RTM 也会有受限制的执行时间、因为 CPU interrupt 会随机 abort 这个 transaction，导致这个事务执行越长、abort rate 越高

   - RTM 在不同的 dataset 上面有不同的效果

8. occ 和 2pl 在长时间运行读操作的事务上的时候、性能都不好（比如说淘宝上的浏览商品）

   - occ 是保守的 abort

9. 所以就有了 MVCC(multi-versioning concurrency control)

   - 首先让这个数据有很多个版本（把数据改成一个 List、里面有值和版本号）
   - 比如说可以让读永远在一个序列化结果的版本上读，写的时候就写到一个新的版本上
   - 解决方法：用一个 global counter，用 atomic fetch-and-add（FAA）来拿到 TX 的开始和 commit time，读和写的时候会拿着这个 counter 去读或者写对应的 snapshot
   - 也会有一个更好的方法，就是原子钟

10. Acquire the start time

    - Phase 1: Concurrent local processing
    - Reads data belongs to the snapshot closest to the start time
    - Buffers writes into a write set

11. Acquire the commit time

    - Phase 2: Commit the results in critical section
    - Commits: installs the write set with the commit time

12. 好处：read 不用做 validation

13. 但是会有一种情况、就是读在写后开始的时候、可能读会读不到还没写的数据（所以需要保证写的原子性）

14. 所以要保证读的 snapshot 内容是需要保证写完的，所以可以在写之前加锁

15. MVCC 保证了 read 没有 race、但是 writes 会有

    - 所以还需要做简单的 validation
    - During commit time, check whether another TX has installed a new snapshot after the committing TX’s start time
    - P48 示意图

16. The MVCC without the read validation is also called snapshot isolation (SI)

    - 做了 read validation 之后才是 MV-OCC 的

17. transaction 的概念不仅在数据库里面有用、在分布式系统里面也有用
