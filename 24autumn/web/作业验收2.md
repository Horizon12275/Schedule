答辩之前可以先问一下舍友关于深度学习的作业问了哪些内容、以及其他作业问了哪些内容。

## hw8

切换到mongoDB分支，然后打开mysql，neo4j，mongoDB，kafka容器、使用微服务的架构启动项目（eureka、gateway、backend、frontend）

1. 将你认为合适的内容改造为在MongoDB中存储，例如整张Book表，或者Book中的封面图片、内容介绍或书评。你可以参照课程样例将数据分别存储在MySQL和MongoDB中，也可以将所有数据都存储在MongoDB中，如果采用后者，需要确保系统功能都能正常实现，包括书籍浏览、查询、下订单和管理库存等。A.	能够正确实现MongoDB与MySQL融合的数据存储和处理方案。(3分)

    - 在navicat中导出对应的json数据、然后通过nodejs脚本将数据导入到mongoDB里面。其中每本书的简介数据对应于一个document、存在一个collection里面。

    - 这里通过BookInfo实体类对mongoDB中的数据进行了对应操作，所有的document都存在了一个叫bookinfo的collection里面。

    - 打开BookDaoMongoImpl类、其中有相关mysql+mongoDB融合的实现代码。这里具体的实现是把mysql里的id和mongoDB的每个bookInfo的document里的id对应起来。

    - 打开navicat、展示mysql中book表不含有简介数据，而mongoDB中bookinfo collection含有简介数据，说明info数据确实是从mysql迁移到了mongoDB。

    - 对书本的更新、添加、删除、查找、下订单操作都进行了测试，应该没有问题。

2. 为你的每一本图书都添加一些标签，表示这些图书的类型分类。在Neo4J中将这些标签构建成一张连通图（或者是一棵树），表示这些标签之间的关系，例如，Fiction与Scientific Fiction之间有边连接，表示后者是前者的细分分类。在系统中增加一项搜索功能，如果用户按照标签搜索，你可以将Neo4J中存储的与用户选中的标签以及通过2次边连接可以关联到的所有标签都选出，作为搜索的依据，在MySQL中搜索所有带有这些标签中任意一个或多个的图书，作为图书搜索结果呈现给用户。B.	能够正确实现图书标签图在Neo4J中的构建与存储，并实现针对标签图的模糊搜索功能(2分)

    - 构建了如下的neo4j中的图数据，表示tag之间的关系。打开neo4j的浏览器http://localhost:7474/browser/，输入`MATCH (n) RETURN n`可以看到所有的节点和关系。

    - 在mysql中预先编辑了每个tag和每个book的对应关系、通过了一个Tag的实体类和TagRepository接口进行对应的查询操作。

    - 通过TagNeo类来对neo4j中的tag数据进行操作，包括了对tag的初始化操作。以及在TagNeoRepository中使用了cypher语句来进行对应的查询操作。将Neo4J中存储的与用户选中的标签以及通过2次边连接可以关联到的所有标签都选出，作为搜索的依据。

    - 在BackendApplication的CommandLineRunner中设置了启动时初始化连接到的neo4j的数据。就是通过java语句的方式将tag数据导入到neo4j里面。

    - 然后在BookController里面写入了对应的搜索功能，通过tag的id来搜索对应的书本。searchBookByTag。在对应的BookServiceImpl里面写入了对应的实现。首先先从neo4j中查找到和这个tag相关的所有tag、放到一个tag list中，然后根据这个tag list、从mysql中查找到所有的图书。

## hw9

1.	请你在自己的机器上安装 InfluxDB，并像课程上所演示的一样监控你的笔记本电脑的状态，在Web界面的Explore中截图贴在Word文档中，并根据截图简要说明一下你的笔记本电脑的运行状态。

    - 首先需要在宿主机上打开telegraf `telegraf --config telegraf.conf`

    - 通过docker-compose文件启动的influxdb的容器、其中设置了对应的token和账号密码

    - 打开influxdb容器、然后进入web控制台、输入账号密码 admin 12345678  然后可以在左侧的data explorer中进行对应的查询操作，可以设置查看的时间范围时最近5分钟、会明显一点，可以看内存和cpu的状态

    - 第一张图中监测了电脑中cpu的所有24个核在近5分钟内的运行占用情况，打开高cpu占用软件后、发现cpu占用有明显变化，说明telegraf监测到了cpu运行状态的变化

    - 第二张图中监测了电脑中内存的占用与空闲内存的情况、打开高内存占用软件后、发现监测的内存占用提高、关闭该软件后、发现内存占用情况恢复、说明telegraf监测到了内存占用情况的变化

2.	请你用Word文档回答下面的问题：

    - 请阐述日志结构数据库中的读放大和写放大分别是什么意思？(2分)

        - 读放大：由于在LSM-tree中、是分层存储数据的，有时候读取某个数据项时需要读取比原数据规模更大的的数据内容。比如如果不使用布隆过滤器去做优化、当读一个数据库中不存在的值的时候，会需要从L0层的SSTable一直读到最后一层的SSTable、直到检查完了所有的SSTable、导致读的开销巨大。

        - 写放大：每次写操作导致实际进行写操作的总数据量超过了原始写入的数据量。当进行单次写操作的时候，会涉及到SSTable的合并（L0层满时将阻塞内存到磁盘的Flush过程），如果这种合并的情况可能会一直延续到最后一层的SSTable、导致这次单次写操作的开销就变得巨大。

    - 请阐述向量数据库中两种以上不同的相似度计算方法中所采用的具体计算方式？(1分)

        - 向量数据库中的相似度计算方法用于衡量向量之间的相似度，常见的计算方式包括**余弦相似度 (Cosine Similarity)**、**欧几里得距离 (Euclidean Distance)** 和**点积 (Dot Product)**，每种方法采用不同的计算方式。以下是它们的具体计算方式：

        ### 1. **余弦相似度 (Cosine Similarity)**

        余弦相似度衡量的是两个向量在角度上的相似度，忽略它们的大小，仅关注方向。它的计算方式如下：

        $
        \text{Cosine Similarity}(A, B) = \frac{A \cdot B}{\|A\| \|B\|}
        $

        其中：

        - \(A $\cdot$ B\) 是向量 \(A\) 和 \(B\) 的点积。
        - \(\|A\|\) 和 \(\|B\|\) 分别是向量 \(A\) 和 \(B\) 的模（即它们的长度）。

        **范围**：余弦相似度的值范围是从 -1 到 1：

        - 1 表示两个向量完全相同（方向相同）。
        - 0 表示两个向量正交（无关）。
        - -1 表示两个向量完全相反（方向相反）。

        ### 2. **欧几里得距离 (Euclidean Distance)**

        欧几里得距离用于计算两个向量之间的直线距离，衡量它们在空间中的"相离"程度。其计算方式为：

        $
        \text{Euclidean Distance}(A, B) = \sqrt{\sum_{i=1}^{n} (A_i - B_i)^2}
        $

        其中：

        - \($A_i$\) 和 \($B_i$\) 是向量 \($A$\) 和 \($B$\) 在第 \(i\) 个维度上的分量。

        **范围**：欧几里得距离的值从 0 到正无穷大：

        - 0 表示两个向量完全相同。
        - 越大的值表示向量之间的差异越大。

        ### 3. **点积 (Dot Product)**

        点积是一种简单的相似度度量，表示两个向量在某种程度上的"投影"关系。其计算方式为：

        $\text{Dot Product}(A, B) = \sum_{i=1}^{n} A_i B_i$

        其中：

        - \($A_i$\) 和 \($B_i$\) 是向量 \($A$\) 和 \($B$\) 在第 \($i$\) 个维度上的分量。

        **范围**：点积的值范围是从负无穷大到正无穷大：

        - 正值表示两个向量的方向相似（指向相同或相似方向）。
        - 0 表示两个向量正交（方向无关）。
        - 负值表示两个向量方向相反。

        ### 总结：

        - **余弦相似度**：衡量向量之间的角度差异，范围从 -1 到 1。
        - **欧几里得距离**：衡量向量之间的直线距离，范围从 0 到正无穷。
        - **点积**：衡量向量在同一方向上的投影大小，范围从负无穷大到正无穷。

        不同的相似度计算方法适用于不同的应用场景，例如，余弦相似度适用于文本数据中的向量相似性比较，欧几里得距离常用于几何计算，而点积则常用于机器学习中的特征向量相似度计算。

## hw10

这里如果要演示的话、可以先用当前打开的后端演示第二个作业，再演示第一个作业。

1.	请你在自己的机器上安装Nginx，并像上课举例一样运行同一个应用的两个实例，然后让Nginx来作为网关转发请求。请你在nginx.conf中依次运行三种不同的转发策略，以及对两个实例配置不同的权重，将运行结果截图贴在Word文档中，并根据截图详细叙述各种配置下运行结果的差异，并分析产生这种差异的原因。

    - 如果不要求演示的话、可以打开word文档进行阐述

    - 演示的话需要先把后端几个实例关了、然后再打开老师课上的那个例子

    - 同时打开nginx容器、如果每次更改配置的话、重启一下容器就行了

    - 发请求到`http://localhost:8000`，然后在nginx的配置文件中配置对应的转发策略，然后再发请求、查看返回的结果

    - 配置文件是 nginx.conf，里面有对应的配置策略

2.	请你使用GraphQL在你的电子书店中实现按照书籍名称来查找书籍的功能，需注意以下问题：

    - 后台实现在数据库中进行数据查找的DAO、Service、Repository、Entity层的代码应该复用你现有的代码。

    - 前端发送的GraphQL请求应该使用变量，以复用查询语句。

    - 请求是发到`http://localhost:8080/graphql`的，可以在这里进行测试。
    
    - 前端的发请求的代码在graphqlService.jsx里面

    - 后端和graphql相关的代码在resource中的schema.graphqls文件里面，然后在BookController里面又加了一个接口，和schema.graphqls里面的查询函数对应，实现了使用在前端利用graphql进行查询的功能。

        ```java
        @QueryMapping
        public Book bookByTitle(@Argument String title) {
            return bookService.searchBookByTitle(title);
        }
        ```

## hw11

1. 请你在大二开发的E-Book系统的基础上，参照上课演示的案例，将E-Book系统实现容器化部署，满足以下要求：
    A.	你的后端Spring Boot项目和MySQL数据库以Compose形式实现容器化部署。
    B.	MySQL数据库容器使用Bind Mount的方式绑定数据库文件目录，这样当你重启MySQL的容器后，数据仍旧不会丢失。考虑到实现难度，此项要求不满足可以不扣分，但你应该去尝试，并且如果不成功，在提交的文档中要描述你遇到的问题。

    - 在backend的项目下有Dockerfile文件
    
    - 在docker文件夹下有Docker-compose文件，实现了mysql的挂载、以及后端的容器化部署

    - 这里需要切换分支到docker分支，然后直接一键打开docker compose的容器即可，这里还需要打开mongoDB和neo4j的容器

    - 这里的库存经过测试、是可以正常进行更新的、其余等比如通过neo4j的tag操作也是正常的

2. 完成“作业11 卷积神经网络.ipynb”中的要求：	参照上课给出的卷积神经网络进行CIFAR-10分类的案例，构建你自己的CNN网络，使CIFAR-100数据集的分类正确率达到45%以上。

    - 详细注释在对应代码里面

## hw12

1. 使用Spark，在你的E-BookStore中增加如下的功能：

    - 将你的系统中所有图书的简介按照图书类型分别存储到多个文本文件中，例如，所有计算机类图书的简介存储在CS.txt中，科幻小说的简介存储在Fiction.txt中。请构建多个这样的文件，作为并行作业的对象。
    - 编写一个关键词列表，包含若干单词，例如，["Java","JavaScript","C++","Programming","Star","Robot"]等。
    - 编写一个Spark程序，将你的文件读入到内存中变成RDD，通过MR作业来统计所有图书简介中每个关键词出现的次数。

启动官方给的docker compose文件之后、然后在localhost:8080上可以看到spark的web ui

docker exec -it hw12-spark-1 bash

然后用script里面的指令输进去就好了、这里挂载了对应的hw12目录到容器里

具体的python代码在hw12app.py中、其中有详细的注释

```bash
spark-submit \
  --class "hw12app" \
  --master local \
  /hw12/hw12app.py
```

输入在input文件夹下。

最后结果在results.txt文件里，可以看到每个关键词在对应的txt文件里出现的次数

2.	完成“作业12 循环神经网络.ipynb”中的要求：

    - 你可以使用Keras来构建和训练自己的循环神经网络RNN和LSTM，并通过调整超参数使你的模型的能够准确预测比特币的价格。
    - 你应该通过参数优化来提升你的模型的准确性，使其预测误差尽量小。

这里的LSTM训练之前、需要重新做一下数据预处理、不然会最终训练不出来东西。

具体注释在对应的代码里
