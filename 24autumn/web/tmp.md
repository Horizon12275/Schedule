## Hive

1. hive是在hadoop基础上发展起来的数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。

2. 要在低版本的java8上运行

3. 很多数据仓库仍然用的是hive去做metadata的store

4. 数据仓库和数据库最大的区别就是它是schema on read的状态。大量的数据仍然是以原始文件的状态存储在hdfs上面、然后hive在上面去读取这个hdfs里的内容。

5. 然后sql不可能直接执行在csv这种文件格式上、所以，hive会先将这些文件做处理、然后转成一种中间格式、最常见的是parquet格式。

6. csv加载进来的dataframe之后、有些内容字段会为空、所以会在进行LOAD DATA操作的时候、不会先做预处理（不做ETL操作、不做校验、数据清洗转换和加载）、直到SQL（做在这个数据上面的分析时）的时候才会执行变成parquet的操作。这个是schema on read的特性。

7. 初始化hive的时候、可以填进去一个<db type>，默认是derby、存的是metadata的信息。如果是derby的话、就是存储在内存里面、也可以存储在mysql里面，但是要告诉具体的位置在哪。

8. 也可以做分区、之后做搜索的时候就可以定位到一个分区里了

9. parquet为什么是列存的？因为做的是OLAP、就是在线的分析处理、都是会对同一列的数据进行操作、所以列存储的效率会更高。

10. 同样是sql、为什么要存到hive里而不是mysql的？因为hive支持很多数据格式。而且hive执行sql表格的来源是多样的、不仅仅是mysql table，还可以是csv等等。

11. Metastore是hive的元数据存储的地方、hive的元数据存储在metastore里面、metastore是一个数据库、存储了hive的元数据信息、比如表的信息、表的结构、表的列、表的分区等等。可以分成独立的进程、也可以和hive在一起。

12. 是schema on read的状态、所以在hive里面、不会对数据做任何的校验和处理、只有在query查询的时候才会做处理。（好处就是一开始只需要直接拷过来、然后就很快）（而且场景是大量的数据、不可能一开始就做处理，多种数据源情况下的一个选择）

13. schema on write的状态、就是在写入的时候就会做处理、比如mysql、写入的时候就会做校验、数据清洗、转换等等。（查询的数据块，因为查询的时候就不用校验了）

14. （会把tables或者partitions进一步地划分成小的buckets）用buckets、查询方便，进一步减少查询的数据量。而且会做分布存储、不同的bucket会存储在不同的地方、这样查询的时候就会更快。也可以保证机器学习中采样的效率、保证整体的采样和部分的采样的一致性。（如果是按照性别区分的buckets）

15. 存储的时候、会把表拆成不同的列族，变成HBase。然后RCFile是会先吧几个行组织成row group、然后在这个row group 里面再按照列进行存储。就有助于OLAP的查询。

16. ORCFile就是优化过的RCFile。会有Index data、row data、stripe footer。这样就可以快速定位到数据的位置、然后直接读取数据。（index data存的就是row data中的block的offset）

17. 重复数据多的时候、同样会有优化、比如只存变化量

18. 压缩率高、存储的时候会压缩、查询的时候会解压缩，所以会需要做权衡

## Flink

1. 事实上的流式数据处理的框架。

2. 在spark里、在微观上会把时间轴切成很小的时间窗、然后宏观上是流处理、微观上是批处理。

3. flink要支持有状态的处理、就是处理后面事件的时候、要知道前面的状态是什么。比如统计一个小时内的数据、就要知道前面的数据是什么。

3. 它可以支持有界或者无界的流式数据

4. 几个概念：streams

5. state

6. time

    - 所有的事件都有一个时间戳。
    - 有一个产生事件的时间、有一个处理的时间。

7. 有 layered api

    - 如果关心业务、可以用高层的table api
    - 如果需要从流的角度去处理、可以用中间的datastream api
    - 如果需要更底层的操作、可以用底层的process function（流是由一堆事件组成的、可以对这些事件进行操作）

8. 先演示了一个最底层的api、process function，这个例子是说要计算一个事件的开始时间和结束时间之间的时间差，需要在start的时候开始记录并等待、然后在end的时候计算时间差。如果等待超过了4h、就会停止等待这个事件。

9. 这个datastream api的例子、就是分一段固定的时间时、做map reduce

10. 状态是怎么保存的、是放在内存或硬盘上、处理的时候会要读这个状态、内存不大的时候、需要存到硬盘上、会影响性能。每个程序只能访问自己的本地的state、不能访问其他设备上的state。为了保证一致性、需要做state的snapshot快照，那么核心问题就是要给哪些东西做快照。