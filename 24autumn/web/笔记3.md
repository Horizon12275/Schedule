## 17 Log-Structured Database & Vector Database

1.  先讲了需要给 redis 的信息加入一个超时的时间，如果一开始的时候、就把所有书都放入到 redis 里，当 3600s 到了之后，那么这些 book 对象全部失效了，那么大量的访问书的请求就需要重新去数据库里拿。这个情况就是雪崩的情况。如何解决呢、比如说可以把这个 10K 的分成 10 个 1K 的，然后让他们逐个失效。第二个情况是、如果 10w 个请求同时读一个不在 redis 里的数据、不加处理的话、会导致 10w 个全部往数据库里去拿、这个就是击穿的情况。如何解决呢、可以加一个锁，当所有请求都访问一个数据的时候、只有一个请求去数据库里拿。第三个情况是，大量访问数据库中不存在的数据，那么全都会访问数据库，这个就是缓存的穿透现象。如何解决呢，可以在前面做一个过滤、比如用布隆过滤器，可以马上告诉你这个数据不在数据库里。（穿透其实是一种攻击）

2.  日志结构数据库：先前的 mysql、mongo 和 neo4j，都有一个隐含的前提、就是所有的数据访问的次数都是差不多的（体现不出新订单和旧订单访问次数的差异（没法处理热点数据的处理情况）（可以用 partition 做、但是还是需要用 timestamp 做、再根据其他字段做子分区也不方便）），所以就有了日志结构数据库。

3.  日志结构数据库用了 LSM-tree

    - Log 需要提高写入性能
    - Log 以 Append 的模式追加写入，不存在删除和修改
    - 这种结构虽然大大提升了数据的写入能力，却是以牺牲部分读取性能为代价，故此这种结构通常适合于写多读少的场景
    - C0 树（常驻内存）
    - C1-N 树(位于磁盘)

4.  因为要落盘的时间、所以会有 immutable memtable （rockdb 做了优化、这个 immutable table 可能会有多个）

5.  要先写到 WAL log （write ahead log）里面、才能再写到内存里面

6.  优点

    - 大幅度提高插入（修改、删除）性能
    - 空间放大率降低（可能会产生不同版本的数据，一个数据多个版本在里面的话、空间放大率就会变大）
    - 访问新数据更快，适合时序、实时存储（适合存双十一的订单）
    - 数据热度分布和 level 相关（经常不被访问到的数据就会沉到底层）

7.  缺点

    - 牺牲了读性能（一次可能访问多个层）
    - 读、写放大率提升

8.  ppt p6 有 sstable 的定义

9.  会有一个 shared key 的概念、就是 abcd、abcd、abcf 前面共同的前缀 abc 就是 shared key（一个同样的 shared key 会存在一个 record group 里面）

10. 写放大：一直要合并到最后一层的时候，会涉及到很多层的合并

11. L0 是无序的，L1-Ln 是有序的

12. 读放大：比如读一个 key=61 的，但是不存在这个数据库里，如果每一层都找不到、就要一路找到最底层（如果不存在布隆过滤器的时候）

13. 老的数据也会在 compaction 的时候被 remove 掉（所有的 sstable 都不可更改、都是在 compaction 的时候重新写进行处理的）

14. 给出的 rocksdb 的例子是嵌入式执行的

15. 热点数据不是一个大量的数据，只需要尽可能快地访问到热点数据就可以了。如果热点数据不再成为热点数据之后、应该把高层的数据放到其他的数据库里（因为会有读放大和写放大）

16. HTAP Hybrid Transactional/Analytical Processing 混合事务分析处理 （这里提到了数据是应该按行存储还是按列存储）（因为在一个系统里面，下面这两种需求都会有，最好不要只有一种、应该混合，或者也可以按行存一轮、按列存一轮（但是也会有缺点、就是空间的浪费和维护一致性的两个问题））

17. Online Transaction Processing(OLTP) （要对随机的读写做支持，要做索引的维护、随机访问数据，可以按行存）（这里就不能按列存、因为需要在不同列地方存同一个订单的信息）

    - 在线事务处理（订单之类的）

    - 低延迟
    - 高并发
    - 数据量小

18. Online Analytical Processing(OLAP)

    - 在线分析处理（统计之类的）（这个如果按行存储的话、导致每一行的长度不一样、会造成很多的随机访问、所以可以按列存储，这样按顺序读就很快）

    - 高延迟
    - 低并发
    - 大量数据

19. LSM-Tree 抽象结构

    - 分层结构
    - 提供写优化
    - TP 事务友好

20. 这里有一个列族的概念（相当于垂直分区，但是管理起来比较麻烦、但是 LSM-tree 在 rocksDB 里面可以支持（可以共用一个 WAL 日志和 manifest files）

    - 比如说可以对和 sale 相关的信息用列存、然后做 OLAP、放在一个列族里面，用 lsm-tree 来存储列信息
    - 然后其他的数据用 row 存、然后支持 OLTP、存在另一个列族里面，用 lsm-tree 来存储行信息

21. 写阻塞问题降低了 TP 事务的可用性，读放大问题限制了 AP 查询的性能

22. 解决写阻塞问题，在 RocksDB 和数据源之间增加一个收集分发层，写阻塞时缓存数据（collector）（基于 apache flink）

    - 采用中心化设计：
      Master 采用主从备份
      监控集群负载，
      调控负载均衡。

    - 负载均衡策略基于剩余内存大小，
      即分配到某个节点的概率与剩余内存大小正比

23. 解决读放大问题：在 RocksDB 中增加列式存储，列式存储在访问少量列时磁盘读取量更小，可以减少读放大的开销（列式存储也是按照数据块的）

24. 提出混合存储策略

    - 常做事务的数据以行式存储，
    - 常做查询的数据以列式存储

25. 然后讲向量数据库

    - 会有 one-hot 编码（所有的单词的点积为 0，每个单词都无关、但是这个缺点就是需要的维数太大）
    - 也会有一个对一个人的各种特征做向量化的处理（降维，然后可以计算两个向量之间的相似性，最后得到的数字都是数值型的，然后找最相似的时候，就去找和向量最相似的（最 naive 的方法，其实需要做更多预处理））
    - 所以向量数据库就是先存、然后做搜索（范围内的搜索，区别就是不是精确匹配、找的是最相似的，和 mongo 的 2d 的区别就是向量数据库支持更高维的）

26. 数据插入向量数据库之后也会需要做索引

27. 随机投影：为了降低数据的维数

    - 用一个随机的矩阵 random matrix generator，然后把原来的数据乘上这个矩阵，就可以得到一个降维或者升维的数据

28. 建立索引的时候、还可以做一个 product quantization，就是把向量分成几个部分，然后每个部分再做一个聚类（通过 codebook generator 转化成 code，然后查找的时候也把查找的 vector 变成多个 code 进行匹配）（比如就是把 500 种组合压缩成 10 种 code，这样就可以做近似匹配（因为不需要做精确匹配））

29. 还可以做位置敏感哈希 locality sensitive hashing，通过 hash 值决定它在哪个 bucket 里面，然后 query 的时候还是找最近的

30. HNSW（hierarchical navigable small world）就是多层的索引

31. 相似度计算：

    - 余弦相似度 Cosine similarity：It ranges from -1 to 1, where 1 represents identical vectors, 0 represents orthogonal vectors, and -1 represents vectors that are diametrically opposed. $\text{Cosine Similarity}(A, B) = \frac{A \cdot B}{|A| |B|}$

    - Euclidean distance: 
      It ranges from 0 to infinity, where 0 represents identical vectors, and larger values represent increasingly dissimilar vectors.

    - Dot product: 
      It ranges from -∞ to ∞, where a positive value represents vectors that point in the same direction, 0 represents orthogonal vectors, and a negative value represents vectors that point in opposite directions.

32. 向量数据库中的相似度计算方法用于衡量向量之间的相似度，常见的计算方式包括**余弦相似度 (Cosine Similarity)**、**欧几里得距离 (Euclidean Distance)** 和**点积 (Dot Product)**，每种方法采用不同的计算方式。以下是它们的具体计算方式：

### 1. **余弦相似度 (Cosine Similarity)**

余弦相似度衡量的是两个向量在角度上的相似度，忽略它们的大小，仅关注方向。它的计算方式如下：

$
\text{Cosine Similarity}(A, B) = \frac{A \cdot B}{\|A\| \|B\|}
$

其中：

- \(A $\cdot$ B\) 是向量 \(A\) 和 \(B\) 的点积。
- \(\|A\|\) 和 \(\|B\|\) 分别是向量 \(A\) 和 \(B\) 的模（即它们的长度）。

**范围**：余弦相似度的值范围是从 -1 到 1：

- 1 表示两个向量完全相同（方向相同）。
- 0 表示两个向量正交（无关）。
- -1 表示两个向量完全相反（方向相反）。

### 2. **欧几里得距离 (Euclidean Distance)**

欧几里得距离用于计算两个向量之间的直线距离，衡量它们在空间中的"相离"程度。其计算方式为：

$
\text{Euclidean Distance}(A, B) = \sqrt{\sum_{i=1}^{n} (A_i - B_i)^2}
$

其中：

- \($A_i$\) 和 \($B_i$\) 是向量 \($A$\) 和 \($B$\) 在第 \(i\) 个维度上的分量。

**范围**：欧几里得距离的值从 0 到正无穷大：

- 0 表示两个向量完全相同。
- 越大的值表示向量之间的差异越大。

### 3. **点积 (Dot Product)**

点积是一种简单的相似度度量，表示两个向量在某种程度上的"投影"关系。其计算方式为：

$\text{Dot Product}(A, B) = \sum_{i=1}^{n} A_i B_i$

其中：

- \($A_i$\) 和 \($B_i$\) 是向量 \($A$\) 和 \($B$\) 在第 \($i$\) 个维度上的分量。

**范围**：点积的值范围是从负无穷大到正无穷大：

- 正值表示两个向量的方向相似（指向相同或相似方向）。
- 0 表示两个向量正交（方向无关）。
- 负值表示两个向量方向相反。

### 总结：

- **余弦相似度**：衡量向量之间的角度差异，范围从 -1 到 1。
- **欧几里得距离**：衡量向量之间的直线距离，范围从 0 到正无穷。
- **点积**：衡量向量在同一方向上的投影大小，范围从负无穷大到正无穷。

不同的相似度计算方法适用于不同的应用场景，例如，余弦相似度适用于文本数据中的向量相似性比较，欧几里得距离常用于几何计算，而点积则常用于机器学习中的特征向量相似度计算。

32. 也可以通过向量的元数据进行过滤，然后再进行匹配
