## deep learning

1. 本质上就是通过一系列函数的线性组合去模拟出最终数值变化的函数

2. 欠拟合：神经元太少，模型太简单，不能很好地拟合数据

3. 过拟合：神经元太多，模型太复杂，对训练数据过度拟合，泛化能力差

4. 所以根据问题的规模、选择合适的模型大小

5. sigmod 的缺点就是梯度消失，（因为最大的一层的梯度为 0.25，然后再往前传的时候，梯度就会越来越小，导致前面的神经元的权重更新很慢）

6. 最后的模式里面、蓝色的是权重小的、红色的是权重大的（好像这个图不太对，因为有很多层，如果把隐藏层减掉就是差不多的了）

7. 卷积几次之后、特征已经变得更复杂了（模式的组合），所以需要池化降低维度

8. 填充：为了结果不要太小

9. 通道数：会影响到特征的提取，如果通道数太少，可能会丢失一些特征，如果通道数太多，可能会增加一些噪声，但是也能提取更多特征

10. 池化：最大值池化、平均值池化

    - 最大值池化：保留最大值，减少噪声，保留特征

11. 卷积神经网络：参数更少，适合图像识别任务

## NLP

1. 第一个问题是怎么把一个 word 变成一个 vector

2. 第二个问题可以用一个 BOW（bag of words）来解决

3. 上面就是一句话怎么把它数值化的一个方法，数值化之后，每个单词都是一个向量

4. 然后用卷积核去卷的时候、就能发现三个单词之间有什么关系、然后再池化、就能找到 5 个单词之间有什么关系、所以 CNN 是可以去做 NLP 的、只不过需要进行修改
